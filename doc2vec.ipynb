{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e653dc-3024-4e7e-af94-203314efc063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import csv\n",
    "import itertools\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models.doc2vec import Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec1dc9a-385b-465e-bd8c-af6dde6edc6d",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2300903b-5dd5-44a5-bfb1-ce61b1991402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctly_read_csv(fname):\n",
    "    prep_df = pd.read_csv(fname, converters={\"tokens_rep\": literal_eval, \"tokens\": literal_eval, \"reference\": literal_eval})\n",
    "    return prep_df\n",
    "\n",
    "\n",
    "def add_extra_keywords(df, key_list, n_repeat):\n",
    "    \"\"\"\n",
    "    Takes df and keyword list, adds n_repeat occurances of keyword to new column when found in doc\n",
    "    \"\"\"\n",
    "    df['tokens_rep_extra'] = df['tokens_rep']\n",
    "    for ind in df.index:\n",
    "        match_list = list()\n",
    "        for keyword in key_list:\n",
    "            # Making everything into a bock of text to find broken up keywords\n",
    "            if keyword in \"\".join(df['tokens_rep'][ind]):\n",
    "                match_list.append(keyword)\n",
    "        if len(match_list) > 0:\n",
    "            i = 0\n",
    "            while i < n_repeat:\n",
    "                df['tokens_rep_extra'][ind] = df['tokens_rep_extra'][ind] + match_list\n",
    "                i += 1\n",
    "    return df['tokens_rep_extra']\n",
    "\n",
    "def add_extra_keywords_temp(df, key_list, n_repeat):\n",
    "    \"\"\"\n",
    "    Takes df and keyword list, adds n_repeat occurances of keyword to new column when found in doc\n",
    "    \"\"\"\n",
    "    df['tokens_rep_extra'] = df['tokens_rep']\n",
    "    for ind in df.index:\n",
    "        match_list = list()\n",
    "        tokens_to_raw = \"\".join(df['tokens_rep'][ind])\n",
    "        for keyword in key_list:\n",
    "            n_instances = tokens_to_raw.count(keyword)\n",
    "            i = 0\n",
    "            while i < n_instances:\n",
    "                match_list.append(keyword)\n",
    "                i += 1\n",
    "        if len(match_list) > 0:\n",
    "            i = 0\n",
    "            while i < n_repeat:\n",
    "                df['tokens_rep_extra'][ind] = df['tokens_rep_extra'][ind] + match_list\n",
    "                i += 1\n",
    "    return df['tokens_rep_extra']\n",
    "\n",
    "def only_keywords(df, key_list):\n",
    "    \"\"\"\n",
    "    Will keep only keywords\n",
    "    Right now is returning some blanks, doesn't work on all data sets\n",
    "    \"\"\"\n",
    "    df['tokens_rep_only'] = \"\"\n",
    "    for ind in df.index:\n",
    "        match_list = list()\n",
    "        for keyword in key_list:\n",
    "            # Making everything into a bock of text to find broken up keywords\n",
    "            if keyword in \"\".join(df['tokens_rep'][ind]):\n",
    "                count = 0\n",
    "                while count < \"\".join(df['tokens_rep'][ind]).count(keyword):\n",
    "                    match_list.append(keyword)\n",
    "                    count += 1\n",
    "        if len(match_list) > 0:\n",
    "            df['tokens_rep_only'][ind] = match_list\n",
    "        else:\n",
    "            print(df['doc_index'][ind])\n",
    "            df['tokens_rep_only'][ind] = ['this is bad']\n",
    "    return df['tokens_rep_only']\n",
    "\n",
    "def fake_tokenizer(tokens):\n",
    "    return tokens\n",
    "\n",
    "def get_all_rep_token_strings(token_list):\n",
    "    all_rep_token_strings = []\n",
    "    for d in token_list:\n",
    "        all_rep_token_strings.append(''.join(d))\n",
    "    return all_rep_token_strings\n",
    "\n",
    "def get_key_doc_dict(all_rep_token_strings, doc_ind_list):\n",
    "    # key word, list of document ids that contain it\n",
    "    key_doc_dict = {}\n",
    "    for k in all_key_list:\n",
    "        k = k.strip()\n",
    "        if k:\n",
    "            k_list = []\n",
    "            for i in range(len(all_rep_token_strings)):\n",
    "                if k in all_rep_token_strings[i]:\n",
    "                    k_list.append(doc_ind_list[i])\n",
    "            if k_list:\n",
    "                key_doc_dict[k] = k_list\n",
    "    return key_doc_dict\n",
    "\n",
    "def get_doc_to_keyword_lst_dict(key_doc_dict):\n",
    "    # dict with doc_id as key and list of keywords in it\n",
    "    doc_to_keyword_lst_dict = {}\n",
    "    for k,lst in key_doc_dict.items():\n",
    "        for doc_id in lst:\n",
    "            if doc_id in doc_to_keyword_lst_dict:\n",
    "                doc_to_keyword_lst_dict[doc_id].append(k)\n",
    "            else:\n",
    "                doc_to_keyword_lst_dict[doc_id] = [k]\n",
    "    return doc_to_keyword_lst_dict\n",
    "\n",
    "def get_doc_to_docs_with_overlap_dict(doc_to_keyword_lst_dict):\n",
    "    # get list of lists of overlapping keys per document\n",
    "    doc_to_docs_with_overlap_dict = {}\n",
    "    for doc_id, keywords_lst in doc_to_keyword_lst_dict.items():\n",
    "        keyword_set = set(keywords_lst)\n",
    "        for doc_id_next, keywords_lst_next in doc_to_keyword_lst_dict.items():\n",
    "            if doc_id_next != doc_id:\n",
    "                keyword_set_next = set(keywords_lst_next)\n",
    "                intersection = keyword_set.intersection(keyword_set_next)\n",
    "                if intersection:\n",
    "                    if doc_id in doc_to_docs_with_overlap_dict:\n",
    "                        doc_to_docs_with_overlap_dict[doc_id][doc_id_next] = intersection\n",
    "                    else:\n",
    "                        doc_to_docs_with_overlap_dict[doc_id] = {doc_id_next: intersection}\n",
    "    return doc_to_docs_with_overlap_dict\n",
    "\n",
    "def rank_most_similar_documents(input_doc_embedding, all_docs_embeddings):\n",
    "    \"\"\"\n",
    "    Get top n matched documents plus their indexes\n",
    "    Return list of tuples where first position in each tuple is index and second position is the probability\n",
    "    \"\"\"\n",
    "    distances = cosine_similarity(input_doc_embedding, all_docs_embeddings)[0]\n",
    "    results = zip(range(len(distances)), distances)\n",
    "    results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "    res_with_doc_index = []\n",
    "    return results\n",
    "\n",
    "def rank_most_similar_documents_docid(input_doc_embedding, all_docs_embeddings, doc_ids_all_embeddings):\n",
    "    \"\"\"\n",
    "    Get top n matched documents plus their indexes\n",
    "    Return list of tuples where first position in each tuple is index and second position is the probability\n",
    "    \"\"\"\n",
    "    distances = cosine_similarity(input_doc_embedding, all_docs_embeddings)[0]\n",
    "    results = zip(doc_ids_all_embeddings, distances)\n",
    "    results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "    res_with_doc_index = []\n",
    "    return results\n",
    "\n",
    "def rank_all_embeddings(all_embeddings, doc_index_list):\n",
    "    rank_probs_all = []\n",
    "    rank_inds_all = []\n",
    "    for i in range(len(doc_index_list)):\n",
    "        rank_results = rank_most_similar_documents(all_embeddings[i], all_embeddings)\n",
    "        rank_probs = []\n",
    "        rank_inds = []\n",
    "        for ind,prob in rank_results:\n",
    "            if ind != i:\n",
    "                rank_probs.append(prob)\n",
    "                rank_inds.append(doc_index_list[ind])\n",
    "        rank_probs_all.append(rank_probs)\n",
    "        rank_inds_all.append(rank_inds)\n",
    "    return rank_probs_all, rank_inds_all\n",
    "\n",
    "def rank_all_keyword_overlap_embeddings(search_df, doc_overlap_dict, all_embeds, id_to_ind):\n",
    "    rank_probs_all = []\n",
    "    rank_inds_all = []\n",
    "    for i in range(len(search_df['doc_index'])):\n",
    "        # get list of embeddings for just the input document\n",
    "        if search_df['doc_index'][i] in doc_overlap_dict:\n",
    "            overlap_inner_dict = doc_overlap_dict[search_df['doc_index'][i]]\n",
    "            overlap_docs = overlap_inner_dict.keys()\n",
    "            overlap_embeds = []\n",
    "            for doc_id in overlap_docs:\n",
    "                the_embed = all_embeds[id_to_ind[doc_id]].toarray().flatten()\n",
    "                overlap_embeds.append(the_embed)\n",
    "            if overlap_embeds:\n",
    "                overlap_embeds = np.stack(overlap_embeds)\n",
    "                #print(overlap_embeds.shape)\n",
    "                rank_results = rank_most_similar_documents_docid(all_embeds[i], overlap_embeds, overlap_docs)\n",
    "                rank_probs = []\n",
    "                rank_inds = []\n",
    "                for d_id,prob in rank_results:\n",
    "                    rank_probs.append(prob)\n",
    "                    rank_inds.append(d_id)\n",
    "                rank_probs_all.append(rank_probs)\n",
    "                rank_inds_all.append(rank_inds)\n",
    "            else:\n",
    "                rank_probs_all.append([])\n",
    "                rank_inds_all.append([])\n",
    "        else:\n",
    "            rank_probs_all.append([])\n",
    "            rank_inds_all.append([])\n",
    "    return rank_probs_all, rank_inds_all\n",
    "\n",
    "def create_guess_output(rank_probs, rank_inds, doc_ids, THRESH):\n",
    "    \"\"\"\n",
    "    Returns a df that contains doc_id and matching reference docs\n",
    "    THRESH controls threshold of match probability   \n",
    "    \"\"\"\n",
    "    probs_to_save = []\n",
    "    inds_to_save = []\n",
    "    for i in range(len(rank_inds)):\n",
    "        this_ind_probs_to_save = []\n",
    "        this_ind_inds_to_save = []\n",
    "        this_ind = 0\n",
    "        prob = rank_probs[i][this_ind]\n",
    "        while prob >= THRESH:\n",
    "            this_ind_probs_to_save.append(prob)\n",
    "            this_ind_inds_to_save.append(rank_inds[i][this_ind])\n",
    "            this_ind += 1\n",
    "            prob = rank_probs[i][this_ind]\n",
    "        probs_to_save.append(this_ind_probs_to_save)\n",
    "        inds_to_save.append(this_ind_inds_to_save)\n",
    "\n",
    "    # Creating output df with index and match\n",
    "    dict_list = list()\n",
    "    for i in range(len(doc_ids)):\n",
    "        if len(inds_to_save[i]) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            for ind in inds_to_save[i]:\n",
    "                new_row = {'Test' :doc_ids[i], \"Reference\": ind}\n",
    "                dict_list.append(new_row)\n",
    "    output_df = pd.DataFrame(dict_list)\n",
    "    return output_df\n",
    "\n",
    "def check_training_results(training_labels_df, guesses_df):\n",
    "    # This is stupid but it works\n",
    "    # Returns f1_measure (AI cup eval metric)\n",
    "    output_touples = [tuple(r) for r in guesses_df.to_numpy()]\n",
    "    training_label_touples = [tuple(r) for r in training_labels_df.to_numpy()]\n",
    "    n_correct_guesses = len(set(output_touples) & set(training_label_touples))\n",
    "    n_correct_guesses\n",
    "    n_guesses = len(output_touples)\n",
    "    n_correct_answers = len(training_label_touples)\n",
    "    precision = n_correct_guesses / n_guesses\n",
    "    recall = n_correct_guesses / n_correct_answers\n",
    "    f1_measure = 2*((precision * recall)/(precision + recall))\n",
    "    # print(\"Correct Guesses: {}\\nNumber of Guesses: {}\\nPrecision: {} \\n Recall: {}\\n Score: {}\".format(n_correct_guesses, n_guesses, precision, recall, f1_measure))\n",
    "    # print(f1_measure)\n",
    "    return f1_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea32ff68-352f-447b-becc-1b9949bf83d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_cosine_matches(df, tfidf, doc_tokens_col, THRESH):\n",
    "    \"\"\"\n",
    "    Processes df, returns guesses df with given doc_tokens_col, threshold, and tfidf\n",
    "    \"\"\"\n",
    "    \n",
    "    doc_tokens = df[doc_tokens_col]\n",
    "    tfidf_embeddings = tfidf.fit_transform(doc_tokens)\n",
    "    \n",
    "    doc_ids = df['doc_index']\n",
    "    rank_probs, rank_inds = rank_all_embeddings(tfidf_embeddings, doc_ids)\n",
    "    \n",
    "    pickle.dump(tfidf, open('tfidf_model.pkl', 'wb'))\n",
    "    pickle.dump(tfidf_embeddings, open('tfidf_embeddings.pkl', 'wb'))\n",
    "\n",
    "    guesses_output = create_guess_output(rank_probs, rank_inds, doc_ids, THRESH)\n",
    "    return guesses_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d24415c-00c7-4dcd-bee0-51b0d6debd22",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f71d2ef-dcd9-4acf-9bd3-5c2da027167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using previous key list to illustrate add_extra_keywords\n",
    "KEYWORD_PATH = 'other_info/Keywords'\n",
    "chem_syn = pd.read_excel(KEYWORD_PATH + \"/02chem.list.xlsx\").fillna(0)\n",
    "crop_syn = pd.read_excel(KEYWORD_PATH + \"/02crop.list.xlsx\").fillna(0)\n",
    "pest_syn = pd.read_excel(KEYWORD_PATH + \"/02pest.list.xlsx\").fillna(0)\n",
    "\n",
    "# chem\n",
    "s_len = chem_syn.shape[0]\n",
    "chem_cols = chem_syn.columns\n",
    "chem_list = list()\n",
    "crop_list = list()\n",
    "pest_list = list()\n",
    "for i in range(s_len):\n",
    "    # find the longest syn.\n",
    "    base_word = chem_syn['synonym1'][i]\n",
    "    for c in chem_cols:\n",
    "        if chem_syn[c][i]!= 0 and len(chem_syn[c][i]) > len(base_word):\n",
    "            base_word = chem_syn[c][i]\n",
    "    chem_list.append(base_word)\n",
    "    \n",
    "\n",
    "# crop\n",
    "s_len = crop_syn.shape[0]\n",
    "crop_cols = crop_syn.columns\n",
    "for i in range(s_len):\n",
    "    # find the longest syn.\n",
    "    base_word = crop_syn['synonym1'][i]\n",
    "    for c in crop_cols:\n",
    "        if crop_syn[c][i]!= 0 and len(crop_syn[c][i]) > len(base_word):\n",
    "            base_word = crop_syn[c][i]\n",
    "    crop_list.append(base_word)\n",
    "            \n",
    "\n",
    "# pest\n",
    "s_len = pest_syn.shape[0]\n",
    "pest_cols = pest_syn.columns\n",
    "for i in range(s_len):\n",
    "    # find the longest syn.\n",
    "    base_word = pest_syn['synonym1'][i]\n",
    "    for c in pest_cols:\n",
    "        if pest_syn[c][i]!= 0 and len(pest_syn[c][i]) > len(base_word):\n",
    "            base_word = pest_syn[c][i]\n",
    "    pest_list.append(base_word)\n",
    "    \n",
    "\n",
    "\n",
    "key_list = (chem_list + crop_list + pest_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba5c9bf-a108-40f7-84a2-7811a57a476b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_index</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>tokens_rep</th>\n",
       "      <th>tokens_num</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>梅雨季來臨文旦黑點病易發生請注意病徵以及早加強防治措施5月已進入梅雨季節近日連續降雨為文旦黑...</td>\n",
       "      <td>[梅雨季, 來臨, 麻豆文旦, 黑點病, 易, 發生, 請, 注意, 病徵, 以, 及早, ...</td>\n",
       "      <td>147</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_index                                           raw_text  \\\n",
       "0          1  梅雨季來臨文旦黑點病易發生請注意病徵以及早加強防治措施5月已進入梅雨季節近日連續降雨為文旦黑...   \n",
       "\n",
       "                                          tokens_rep  tokens_num reference  \n",
       "0  [梅雨季, 來臨, 麻豆文旦, 黑點病, 易, 發生, 請, 注意, 病徵, 以, 及早, ...         147        []  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels = pd.read_csv('other_info/TrainLabel.csv')\n",
    "\n",
    "train_df = correctly_read_csv(\"processed_data_new.csv\")\n",
    "\n",
    "train_df[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1e8ca22-9246-421d-8b1b-50c0dac5cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = train_df['tokens_rep']\n",
    "train_ids = train_df['doc_index']\n",
    "tagged_data = [TaggedDocument(words=train_tokens[i], tags=[str(train_ids[i])]) for i in train_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdb54f60-48de-4516-9549-e7fe42eb2596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f312d68c-950c-487a-8571-09472cba3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec(vector_size=30, min_count=2, epochs = 80)\n",
    "model.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e72d7a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e615b146",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"d2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ef7a19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1005', 0.9590003490447998), ('1007', 0.9016110897064209), ('1015', 0.8284493684768677), ('1133', 0.8246675133705139), ('598', 0.81834477186203), ('279', 0.7886989116668701), ('1369', 0.7857670187950134), ('296', 0.7828602194786072), ('588', 0.7646927237510681), ('305', 0.7568822503089905)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drewc\\AppData\\Local\\Temp/ipykernel_18876/2951008157.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  similar_doc = model.docvecs.most_similar('1000')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "similar_doc = model.docvecs.most_similar('1000')\n",
    "print(similar_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f4ba134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_guess_output_d2v(model, doc_ids, THRESH):\n",
    "    \"\"\"\n",
    "    Returns a df that contains doc_id and matching reference docs\n",
    "    THRESH controls threshold of match probability   \n",
    "    \"\"\"\n",
    "    dict_list = list()\n",
    "    for i in range(len(doc_ids)):\n",
    "        similar_docs = model.docvecs.most_similar(str(doc_ids[i]), topn=len(model.dv))\n",
    "        this_ind = 0\n",
    "        prob = similar_docs[this_ind][1]\n",
    "        while prob >= THRESH:\n",
    "            new_row = {'Test' :doc_ids[i], \"Reference\": int(similar_docs[this_ind][0])}   \n",
    "            dict_list.append(new_row)         \n",
    "            this_ind += 1\n",
    "            try:\n",
    "                prob = similar_docs[this_ind][1]\n",
    "            except:\n",
    "                prob = THRESH-1\n",
    "    output_df = pd.DataFrame(dict_list)\n",
    "    return output_df\n",
    "\n",
    "def check_training_results(training_labels_df, guesses_df):\n",
    "    # This is stupid but it works\n",
    "    # Returns f1_measure (AI cup eval metric)\n",
    "    output_touples = [tuple(r) for r in guesses_df.to_numpy()]\n",
    "    training_label_touples = [tuple(r) for r in training_labels_df.to_numpy()]\n",
    "    n_correct_guesses = len(set(output_touples) & set(training_label_touples))\n",
    "    n_correct_guesses\n",
    "    n_guesses = len(output_touples)\n",
    "    n_correct_answers = len(training_label_touples)\n",
    "\n",
    "    precision = n_correct_guesses / n_guesses\n",
    "    recall = n_correct_guesses / n_correct_answers\n",
    "    print(\"Correct Guesses: {}\\nNumber of Guesses: {}\\nPrecision: {} \\n Recall: {}\\n Score: \".format(n_correct_guesses, n_guesses, precision, recall))\n",
    "\n",
    "    f1_measure = 2*((precision * recall)/(precision + recall))\n",
    "    print(\"Correct Guesses: {}\\nNumber of Guesses: {}\\nPrecision: {} \\n Recall: {}\\n Score: {}\".format(n_correct_guesses, n_guesses, precision, recall, f1_measure))\n",
    "    # print(f1_measure)\n",
    "    return f1_measure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2a1f9d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c7177c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drewc\\AppData\\Local\\Temp/ipykernel_18876/2305025332.py:8: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  similar_docs = model.docvecs.most_similar(str(doc_ids[i]), topn=len(model.dv))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Guesses: 1050\n",
      "Number of Guesses: 14264\n",
      "Precision: 0.07361189007291083 \n",
      " Recall: 0.7592190889370932\n",
      " Score: \n",
      "Correct Guesses: 1050\n",
      "Number of Guesses: 14264\n",
      "Precision: 0.07361189007291083 \n",
      " Recall: 0.7592190889370932\n",
      " Score: 0.1342110308685371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1342110308685371"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_training_results(training_labels, create_guess_output_d2v(model, train_ids, .7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "221e08c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [16:14<00:00, 97.46s/it]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import workers\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "params = {\n",
    "    'vector_size' : list(range(10, 100, 5)),\n",
    "    'min_count' : [1],\n",
    "    'epochs' : [10],\n",
    "    'window' : [1,2,3,4,5],\n",
    "    'dm' : [0],\n",
    "    \"hs\" :[1]\n",
    "    # 'threshold' : [x / 100.0 for x in range(50, 100, 10)],\n",
    "}\n",
    "# parameters_combos = (dict(zip(params.keys(), values)) for values in itertools.product(*params.values()))\n",
    "\n",
    "# print(len(list(parameters_combos)))\n",
    "results_list = list()\n",
    "\n",
    "\n",
    "for x in tqdm([x / 100.0 for x in range(50, 100, 5)]):\n",
    "    params['threshold'] = [x]\n",
    "    parameters_combos = (dict(zip(params.keys(), values)) for values in itertools.product(*params.values()))\n",
    "    pool = multiprocessing.Pool()\n",
    "    results = pool.starmap(workers.multiprocess_doc2vec, zip(parameters_combos, itertools.repeat(tagged_data), itertools.repeat(training_labels), itertools.repeat(train_ids)))\n",
    "    results_list.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa652996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector_size</th>\n",
       "      <th>min_count</th>\n",
       "      <th>epochs</th>\n",
       "      <th>window</th>\n",
       "      <th>dm</th>\n",
       "      <th>hs</th>\n",
       "      <th>threshold</th>\n",
       "      <th>score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.389506</td>\n",
       "      <td>0.364151</td>\n",
       "      <td>0.418655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.388552</td>\n",
       "      <td>0.323699</td>\n",
       "      <td>0.485900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.388500</td>\n",
       "      <td>0.396241</td>\n",
       "      <td>0.381056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.388231</td>\n",
       "      <td>0.411669</td>\n",
       "      <td>0.367317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3366</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.388156</td>\n",
       "      <td>0.383099</td>\n",
       "      <td>0.393348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.387583</td>\n",
       "      <td>0.323643</td>\n",
       "      <td>0.483008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3430</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.386933</td>\n",
       "      <td>0.388484</td>\n",
       "      <td>0.385394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.386925</td>\n",
       "      <td>0.407853</td>\n",
       "      <td>0.368040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3362</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.386911</td>\n",
       "      <td>0.384835</td>\n",
       "      <td>0.389009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.386782</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.372379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.386729</td>\n",
       "      <td>0.381690</td>\n",
       "      <td>0.391902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3130</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.386067</td>\n",
       "      <td>0.322502</td>\n",
       "      <td>0.480839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.385874</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.485900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.385775</td>\n",
       "      <td>0.414452</td>\n",
       "      <td>0.360810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.385737</td>\n",
       "      <td>0.349589</td>\n",
       "      <td>0.430224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.385432</td>\n",
       "      <td>0.319392</td>\n",
       "      <td>0.485900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3306</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.385333</td>\n",
       "      <td>0.347045</td>\n",
       "      <td>0.433116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.385190</td>\n",
       "      <td>0.379383</td>\n",
       "      <td>0.391179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.385133</td>\n",
       "      <td>0.345800</td>\n",
       "      <td>0.434563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.385129</td>\n",
       "      <td>0.321845</td>\n",
       "      <td>0.479393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.384842</td>\n",
       "      <td>0.351013</td>\n",
       "      <td>0.425886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3378</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.383824</td>\n",
       "      <td>0.376741</td>\n",
       "      <td>0.391179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.383577</td>\n",
       "      <td>0.318095</td>\n",
       "      <td>0.483008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3506</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.383479</td>\n",
       "      <td>0.402866</td>\n",
       "      <td>0.365871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.383479</td>\n",
       "      <td>0.402866</td>\n",
       "      <td>0.365871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.383452</td>\n",
       "      <td>0.316682</td>\n",
       "      <td>0.485900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3554</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.383416</td>\n",
       "      <td>0.404494</td>\n",
       "      <td>0.364425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3370</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.383387</td>\n",
       "      <td>0.376569</td>\n",
       "      <td>0.390456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.383357</td>\n",
       "      <td>0.317793</td>\n",
       "      <td>0.483008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3342</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.383280</td>\n",
       "      <td>0.375694</td>\n",
       "      <td>0.391179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.383250</td>\n",
       "      <td>0.357054</td>\n",
       "      <td>0.413594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.383225</td>\n",
       "      <td>0.362581</td>\n",
       "      <td>0.406363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.383137</td>\n",
       "      <td>0.317490</td>\n",
       "      <td>0.483008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.382995</td>\n",
       "      <td>0.407166</td>\n",
       "      <td>0.361533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3458</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.370933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.370933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.382963</td>\n",
       "      <td>0.385630</td>\n",
       "      <td>0.380333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.382894</td>\n",
       "      <td>0.314711</td>\n",
       "      <td>0.488792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.382869</td>\n",
       "      <td>0.317748</td>\n",
       "      <td>0.481562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.382869</td>\n",
       "      <td>0.317748</td>\n",
       "      <td>0.481562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.382783</td>\n",
       "      <td>0.317317</td>\n",
       "      <td>0.482285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.382614</td>\n",
       "      <td>0.316462</td>\n",
       "      <td>0.483731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3450</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.382602</td>\n",
       "      <td>0.390226</td>\n",
       "      <td>0.375271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.382599</td>\n",
       "      <td>0.318008</td>\n",
       "      <td>0.480116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3354</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.382425</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.393348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3434</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.382364</td>\n",
       "      <td>0.392097</td>\n",
       "      <td>0.373102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3074</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.382361</td>\n",
       "      <td>0.315197</td>\n",
       "      <td>0.485900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.382294</td>\n",
       "      <td>0.317271</td>\n",
       "      <td>0.480839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3598</th>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.382185</td>\n",
       "      <td>0.403537</td>\n",
       "      <td>0.362979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.382174</td>\n",
       "      <td>0.343318</td>\n",
       "      <td>0.430947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      vector_size  min_count  epochs  window  dm  hs  threshold     score  \\\n",
       "3334           30          1      10       4   0   1       0.95  0.389506   \n",
       "3142           75          1      10       1   0   1       0.90  0.388552   \n",
       "3446           60          1      10       2   0   1       0.95  0.388500   \n",
       "3462           65          1      10       1   0   1       0.95  0.388231   \n",
       "3366           40          1      10       2   0   1       0.95  0.388156   \n",
       "3198           85          1      10       5   0   1       0.90  0.387583   \n",
       "3430           55          1      10       3   0   1       0.95  0.386933   \n",
       "3486           70          1      10       2   0   1       0.95  0.386925   \n",
       "3362           40          1      10       1   0   1       0.95  0.386911   \n",
       "3442           60          1      10       1   0   1       0.95  0.386782   \n",
       "3374           40          1      10       4   0   1       0.95  0.386729   \n",
       "3130           70          1      10       3   0   1       0.90  0.386067   \n",
       "3094           60          1      10       4   0   1       0.90  0.385874   \n",
       "3470           65          1      10       3   0   1       0.95  0.385775   \n",
       "3302           25          1      10       1   0   1       0.95  0.385737   \n",
       "3134           70          1      10       4   0   1       0.90  0.385432   \n",
       "3306           25          1      10       2   0   1       0.95  0.385333   \n",
       "3358           35          1      10       5   0   1       0.95  0.385190   \n",
       "3310           25          1      10       3   0   1       0.95  0.385133   \n",
       "3102           65          1      10       1   0   1       0.90  0.385129   \n",
       "3318           25          1      10       5   0   1       0.95  0.384842   \n",
       "3378           40          1      10       5   0   1       0.95  0.383824   \n",
       "3206           90          1      10       2   0   1       0.90  0.383577   \n",
       "3506           75          1      10       2   0   1       0.95  0.383479   \n",
       "3538           80          1      10       5   0   1       0.95  0.383479   \n",
       "3038           45          1      10       5   0   1       0.90  0.383452   \n",
       "3554           85          1      10       4   0   1       0.95  0.383416   \n",
       "3370           40          1      10       3   0   1       0.95  0.383387   \n",
       "3222           95          1      10       1   0   1       0.90  0.383357   \n",
       "3342           35          1      10       1   0   1       0.95  0.383280   \n",
       "3330           30          1      10       3   0   1       0.95  0.383250   \n",
       "3338           30          1      10       5   0   1       0.95  0.383225   \n",
       "3210           90          1      10       3   0   1       0.90  0.383137   \n",
       "3474           65          1      10       4   0   1       0.95  0.382995   \n",
       "3458           60          1      10       5   0   1       0.95  0.382979   \n",
       "3454           60          1      10       4   0   1       0.95  0.382979   \n",
       "3418           50          1      10       5   0   1       0.95  0.382963   \n",
       "3078           55          1      10       5   0   1       0.90  0.382894   \n",
       "3122           70          1      10       1   0   1       0.90  0.382869   \n",
       "3138           70          1      10       5   0   1       0.90  0.382869   \n",
       "3114           65          1      10       4   0   1       0.90  0.382783   \n",
       "3154           75          1      10       4   0   1       0.90  0.382614   \n",
       "3450           60          1      10       3   0   1       0.95  0.382602   \n",
       "3126           70          1      10       2   0   1       0.90  0.382599   \n",
       "3354           35          1      10       4   0   1       0.95  0.382425   \n",
       "3434           55          1      10       4   0   1       0.95  0.382364   \n",
       "3074           55          1      10       4   0   1       0.90  0.382361   \n",
       "3150           75          1      10       3   0   1       0.90  0.382294   \n",
       "3598           95          1      10       5   0   1       0.95  0.382185   \n",
       "3314           25          1      10       4   0   1       0.95  0.382174   \n",
       "\n",
       "      precision    recall  \n",
       "3334   0.364151  0.418655  \n",
       "3142   0.323699  0.485900  \n",
       "3446   0.396241  0.381056  \n",
       "3462   0.411669  0.367317  \n",
       "3366   0.383099  0.393348  \n",
       "3198   0.323643  0.483008  \n",
       "3430   0.388484  0.385394  \n",
       "3486   0.407853  0.368040  \n",
       "3362   0.384835  0.389009  \n",
       "3442   0.402344  0.372379  \n",
       "3374   0.381690  0.391902  \n",
       "3130   0.322502  0.480839  \n",
       "3094   0.320000  0.485900  \n",
       "3470   0.414452  0.360810  \n",
       "3302   0.349589  0.430224  \n",
       "3134   0.319392  0.485900  \n",
       "3306   0.347045  0.433116  \n",
       "3358   0.379383  0.391179  \n",
       "3310   0.345800  0.434563  \n",
       "3102   0.321845  0.479393  \n",
       "3318   0.351013  0.425886  \n",
       "3378   0.376741  0.391179  \n",
       "3206   0.318095  0.483008  \n",
       "3506   0.402866  0.365871  \n",
       "3538   0.402866  0.365871  \n",
       "3038   0.316682  0.485900  \n",
       "3554   0.404494  0.364425  \n",
       "3370   0.376569  0.390456  \n",
       "3222   0.317793  0.483008  \n",
       "3342   0.375694  0.391179  \n",
       "3330   0.357054  0.413594  \n",
       "3338   0.362581  0.406363  \n",
       "3210   0.317490  0.483008  \n",
       "3474   0.407166  0.361533  \n",
       "3458   0.395833  0.370933  \n",
       "3454   0.395833  0.370933  \n",
       "3418   0.385630  0.380333  \n",
       "3078   0.314711  0.488792  \n",
       "3122   0.317748  0.481562  \n",
       "3138   0.317748  0.481562  \n",
       "3114   0.317317  0.482285  \n",
       "3154   0.316462  0.483731  \n",
       "3450   0.390226  0.375271  \n",
       "3126   0.318008  0.480116  \n",
       "3354   0.372093  0.393348  \n",
       "3434   0.392097  0.373102  \n",
       "3074   0.315197  0.485900  \n",
       "3150   0.317271  0.480839  \n",
       "3598   0.403537  0.362979  \n",
       "3314   0.343318  0.430947  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list_new = list()\n",
    "for n in range(len(results_list)):\n",
    "    for i in range(len(results_list[n])):\n",
    "        results_list_new.append(results_list[n][i])\n",
    "results_list_new\n",
    "results_df = pd.DataFrame(results_list_new)\n",
    "results_df.nlargest(n=50, columns=['score'])\n",
    "results_df_sorted = results_df.sort_values(by=['score'], ascending=False)\n",
    "results_df_sorted[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a51dff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b928b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43049551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d00dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
