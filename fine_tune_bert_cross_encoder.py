# -*- coding: utf-8 -*-
"""fine_tune_bert_cross_encoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U53QrmmnsRJye0F00unoh6g959dtfMXd
"""

#!pip install sentence_transformers

from sentence_transformers import CrossEncoder, InputExample
from sentence_transformers.cross_encoder.evaluation import CEBinaryClassificationEvaluator
from torch.utils.data import DataLoader
#from google.colab import files

MODEL_NAME = 'bert-base-chinese'

batch_size = 16

model = CrossEncoder(MODEL_NAME, num_labels=2)

# from google.colab import drive
# drive.mount('/content/drive')

def get_examples(fpath):
  examples = []
  fname = fpath.split('/')[-1].split('.')[-2]
  gu_id = 0
  for line in open(fpath, encoding="utf-8"):
    splits = line.strip().split('\t')
    label = int(splits[2])
    text1 = splits[0]
    text2 = splits[1]
    guid = "%s-%d" % (fname, gu_id)
    gu_id += 1
    examples.append(InputExample(guid=guid, texts=[text1, text2], label=label))
  return examples

train_pair_examples = get_examples('all_pairs_balanced.tsv')

print(train_pair_examples[0])

def get_pairs_label_lists(fpath):
  pairs = []
  labels = []
  fname = fpath.split('/')[-1].split('.')[-2]
  for line in open(fpath, encoding="utf-8"):
    splits = line.strip().split('\t')
    label = int(splits[2])
    text1 = splits[0]
    text2 = splits[1]
    pairs.append([text1, text2])
    labels.append(label)
  return pairs, labels

train_data_loader = DataLoader(train_pair_examples, batch_size=batch_size, shuffle=True)

pairs, labels = get_pairs_label_lists('all_pairs_balanced.tsv')

evaluator = CEBinaryClassificationEvaluator(pairs, labels)

model_save_path = 'bert_chinese_doc_pair_ce_classifier'

model.fit(train_dataloader=train_data_loader, epochs=4,
          output_path=model_save_path, evaluator=evaluator, evaluation_steps=500)